{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c6825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Fetching Nancy Pelosi's holdings from PelosiTracker...\n",
      "âœ“ Successfully saved 12 holdings to nancy_pelosi_current_holdings_from_pelositracker.json\n",
      "âœ“ Sample holding: {'Ticker': 'NVDA', 'Last Price': '$190.05', 'Weight': '19%'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_pelosi_holdings(max_retries: int = 3, timeout: int = 10):\n",
    "    \"\"\"\n",
    "    Fetch Nancy Pelosi's current holdings from PelosiTracker with error handling.\n",
    "    \n",
    "    Args:\n",
    "        max_retries: Maximum number of retry attempts\n",
    "        timeout: Request timeout in seconds\n",
    "    \n",
    "    Returns:\n",
    "        List of holding dictionaries\n",
    "    \"\"\"\n",
    "    url = \"https://pelositracker.app/portfolios/nancy-pelosi\"\n",
    "    \n",
    "    # Proper headers to avoid blocking\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Connection': 'keep-alive',\n",
    "    }\n",
    "    \n",
    "    # Retry logic for network requests\n",
    "    resp = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            resp = requests.get(url, headers=headers, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            break\n",
    "        except requests.exceptions.Timeout:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise Exception(f\"Request timed out after {max_retries} attempts\")\n",
    "            print(f\"âš  Timeout on attempt {attempt + 1}/{max_retries}, retrying in {2 ** attempt} seconds...\")\n",
    "            time.sleep(2 ** attempt)  # Exponential backoff\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise Exception(f\"Connection error after {max_retries} attempts: {e}\")\n",
    "            print(f\"âš  Connection error on attempt {attempt + 1}/{max_retries}, retrying in {2 ** attempt} seconds...\")\n",
    "            time.sleep(2 ** attempt)\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if resp and resp.status_code == 404:\n",
    "                raise Exception(f\"Page not found (404). URL may have changed: {url}\")\n",
    "            elif resp and resp.status_code == 403:\n",
    "                raise Exception(f\"Access forbidden (403). Website may be blocking requests.\")\n",
    "            elif attempt == max_retries - 1:\n",
    "                raise Exception(f\"HTTP error after {max_retries} attempts: {e}\")\n",
    "            print(f\"âš  HTTP error {resp.status_code if resp else 'unknown'} on attempt {attempt + 1}/{max_retries}, retrying...\")\n",
    "            time.sleep(2 ** attempt)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise Exception(f\"Request failed after {max_retries} attempts: {e}\")\n",
    "            print(f\"âš  Request error on attempt {attempt + 1}/{max_retries}, retrying in {2 ** attempt} seconds...\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    \n",
    "    if resp is None:\n",
    "        raise Exception(\"Failed to get response after all retry attempts\")\n",
    "    \n",
    "    # Parse HTML with error handling\n",
    "    try:\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to parse HTML: {e}\")\n",
    "    \n",
    "    # Find the holdings table - try multiple strategies\n",
    "    holdings_table = None\n",
    "    \n",
    "    # Strategy 1: Look for table with specific column names\n",
    "    for table in soup.find_all('table'):\n",
    "        try:\n",
    "            headers = [th.get_text(strip=True).lower() for th in table.find_all(['th', 'td'])]\n",
    "            header_text = ' '.join(headers)\n",
    "            if any(keyword in header_text for keyword in ['ticker', 'symbol']) and 'weight' in header_text:\n",
    "                holdings_table = table\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"âš  Warning: Error checking table: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Strategy 2: Look for table containing common tickers (fallback)\n",
    "    if holdings_table is None:\n",
    "        common_tickers = ['NVDA', 'GOOGL', 'AAPL', 'MSFT', 'TSLA']\n",
    "        for table in soup.find_all('table'):\n",
    "            try:\n",
    "                table_text = table.get_text()\n",
    "                if any(ticker in table_text for ticker in common_tickers):\n",
    "                    holdings_table = table\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "    \n",
    "    if holdings_table is None:\n",
    "        raise ValueError(\"Could not find holdings table on PelosiTracker page. Website structure may have changed.\")\n",
    "    \n",
    "    # Extract headers more robustly\n",
    "    headers = []\n",
    "    try:\n",
    "        thead = holdings_table.find('thead')\n",
    "        if thead:\n",
    "            headers = [th.get_text(strip=True) for th in thead.find_all(['th', 'td'])]\n",
    "        else:\n",
    "            # Try first row as headers\n",
    "            first_row = holdings_table.find('tr')\n",
    "            if first_row:\n",
    "                headers = [th.get_text(strip=True) for th in first_row.find_all(['th', 'td'])]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to extract table headers: {e}\")\n",
    "    \n",
    "    if not headers:\n",
    "        raise ValueError(\"Could not extract table headers. Table structure may have changed.\")\n",
    "    \n",
    "    # Extract rows with error handling\n",
    "    holdings = []\n",
    "    try:\n",
    "        tbody = holdings_table.find('tbody')\n",
    "        rows = tbody.find_all('tr') if tbody else holdings_table.find_all('tr')[1:]\n",
    "        \n",
    "        for row in rows:\n",
    "            try:\n",
    "                cells = [td.get_text(strip=True) for td in row.find_all(['td', 'th'])]\n",
    "                if len(cells) >= len(headers):  # Allow extra cells\n",
    "                    holding = dict(zip(headers, cells[:len(headers)]))\n",
    "                    # Basic validation - ensure we have a ticker\n",
    "                    ticker_keys = ['Ticker', 'ticker', 'Symbol', 'symbol']\n",
    "                    if any(holding.get(key) for key in ticker_keys):\n",
    "                        holdings.append(holding)\n",
    "            except Exception as e:\n",
    "                print(f\"âš  Warning: Error processing row: {e}\")\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to extract table rows: {e}\")\n",
    "    \n",
    "    if not holdings:\n",
    "        raise ValueError(\"No holdings found in table. Data may be empty or structure changed.\")\n",
    "    \n",
    "    return holdings\n",
    "\n",
    "# Main execution with comprehensive error handling\n",
    "try:\n",
    "    print(\"ðŸ”„ Fetching Nancy Pelosi's holdings from PelosiTracker...\")\n",
    "    holdings = fetch_pelosi_holdings()\n",
    "    \n",
    "    # Save to JSON with error handling\n",
    "    output_file = \"nancy_pelosi_current_holdings_from_pelositracker.json\"\n",
    "    try:\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(holdings, f, indent=2)\n",
    "        print(f\"âœ“ Successfully saved {len(holdings)} holdings to {output_file}\")\n",
    "        print(f\"âœ“ Sample holding: {holdings[0] if holdings else 'No holdings found'}\")\n",
    "    except IOError as e:\n",
    "        raise Exception(f\"Failed to write JSON file: {e}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error saving data: {e}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"âœ— Validation Error: {e}\")\n",
    "    # Log error\n",
    "    try:\n",
    "        with open(\"scraping_error.log\", \"a\") as f:\n",
    "            f.write(f\"{datetime.now()}: Validation Error - {str(e)}\\n\")\n",
    "    except:\n",
    "        pass\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error: {e}\")\n",
    "    # Log error\n",
    "    try:\n",
    "        with open(\"scraping_error.log\", \"a\") as f:\n",
    "            f.write(f\"{datetime.now()}: {type(e).__name__} - {str(e)}\\n\")\n",
    "    except:\n",
    "        pass\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
